# Colorado Ski Tracker

Pulls weather and snow data from [weather.gov](https://www.weather.gov) for Colorado ski resorts, stores it in SQLite, computes ski scores, and serves a React web app.

---

## Requirements Checklist

| Requirement | How It's Implemented |
|-------------|----------------------|
| **Web application — form & reporting** | React app with a resort lookup form (search by name) and a report showing top 3 resorts plus detailed breakdowns (temperature, wind, snow, conditions scores). `frontend/src/App.tsx` |
| **Data collection** | `data_collector/` service fetches NWS weather and snow data for Colorado resorts via `POST /fetch`. `data_collector/main.py` |
| **Data analyzer** | `data_analyzer/` service computes ski scores from DB data and exposes `GET /scores` and `GET /scores/{resort_name}`. `data_analyzer/main.py` |
| **Unit tests** | Pytest suite in `tests/` for collector, analyzer, and API endpoints. Run via `pytest tests/` |
| **Data persistence** | SQLite database (`/app/data/weather.db`) shared between collector and analyzer via Docker volume `db_data`. `data_collector/database.py`, `docker-compose.yml` |
| **REST collaboration** | Public API endpoints: `POST /fetch`, `GET /scores`, `GET /scores/{resort_name}`, `GET /health`. Internal: `POST /internal/notify` (scheduler → analyzer). `data_collector/main.py`, `data_analyzer/main.py` |
| **Product environment** | Docker Compose stack with `api`, `analyzer`, `scheduler`, `frontend`, `jaeger`, plus healthchecks and service deps. `docker-compose.yml` |
| **Integration tests** | `test_integration_analyzer.py` uses seeded SQLite fixture to exercise the analyzer. `tests/test_integration_analyzer.py`, `tests/conftest.py` |
| **Mock objects / test doubles** | NWS API mocked via `@patch("data_collector.main.httpx.Client")` in `test_api_collector.py` so tests don't hit real HTTP. `tests/test_api_collector.py` |
| **Production monitoring** | OpenTelemetry instrumentation for FastAPI, HTTPX, SQLAlchemy; traces exported to Jaeger. `data_collector/observability.py`, `docker-compose.yml` (jaeger) |
| **Event collaboration / messaging** | Scheduler triggers `POST /fetch` then `POST /internal/notify`. Analyzer exposes `GET /events` (SSE). Frontend subscribes to `/events` and refetches scores on `weather_data_updated`. `scheduler.py`, `data_analyzer/main.py`, `frontend/src/App.tsx` |
| **CI/CD** | **CI:** GitHub Actions runs backend tests and frontend build on push/PR to `main`. `ci.yml` **CD:** Render auto-deploys backend on push to `main`. `cd.yml` documents the process. Live: https://colorado-ski-app.onrender.com |

---

## Setup

Requires [Docker Desktop](https://www.docker.com/products/docker-desktop/).

```bash
docker-compose up --build
```

- **API:** http://127.0.0.1:8000/docs
- **Analyzer:** http://127.0.0.1:8001
- **Frontend:** http://127.0.0.1:5173
- **Jaeger UI:** http://localhost:16686

---

## Architecture

```
scheduler → POST /fetch (api) → writes to SQLite
scheduler → POST /internal/notify (analyzer) → broadcast via SSE
frontend ← GET /events (SSE) ← refetches GET /scores on event
```

---

## Acknowledgments and AI Use

This project utilized **Cursor (Composer 1.5)** to assist in development. Where Cursor was used, I reviewed the output and took responsibility for its correctness and integration.

### AI Tools Used
* **Cursor (Composer 1.5):** Used for generating database boilerplate, models, frontend code, and tests.

### Specific Applications

**Cursor-generated (with minimal edits):**
* **Frontend:** The React app (form, reporting, SSE subscription) was generated by Cursor and edited very little.
* **Tests:** The test suite (mocks, fixtures, integration tests) was generated by Cursor and edited very little.
* **Scheduler:** `scheduler.py` was largely AI-generated.

**Cursor-generated, then refined by me:**
* **Database setup:** SQLAlchemy engine and session configuration.
* **Data modeling:** Initial structures for `Location`, `WeatherRecord`, and `SnowRecord` in `models.py`, then manually refined.
* **Bug fixing:** Troubleshooting `ValueError` from weather.gov ISO strings during database insertion.

**Primarily my work:**
* **Core application logic:** Manual tweaks and refinements to the data collector, analyzer, and event collaboration flow.
* **CI & Docker:** `ci.yml` and `docker-compose.yml` written mostly by hand.
* **Data schema:** Relationships (cascade deletes) and field types in the models.
* **Observability:** `observability.py` written by hand from the OpenTelemetry documentation.
* **README:** Content and structure are mine; used Cursor for formatting and styling.

### Prompts Used

**Data collector** (`data_collector/main.py`):

> Create a FastAPI app that fetches weather from NOAA/NWS api.weather.gov for Colorado resorts (Aspen, Arapahoe Basin, Copper, Keystone, Telluride). Call GET /points/{lat},{lon} to get forecast and forecastGridData URLs. Implement sync_all_weather(db) that creates Location rows if missing, fetches and stores WeatherRecord and SnowRecord. Provide POST /fetch and GET /health. Use httpx.Client with User-Agent. Set up observability before importing database so SQLAlchemy is instrumented.

**Database models** (`data_collector/models.py`):

> Define SQLAlchemy Location (name, lat, lon, forecast_url, gridpoint_url), WeatherRecord (period, times, temp, wind, short_forecast), SnowRecord (valid_time, snowfall_amount, unit). Relationships with cascade delete.

**Data analyzer** (`data_analyzer/main.py`):

> Create a FastAPI service that queries weather and snow data from a shared SQLite database via SQLAlchemy (Location, WeatherRecord, SnowRecord from data_collector.models) and computes a ski score (0–100) for each location. The score has four factors of 25 points each: temperature (ideal 15–30°F), wind (lower is better), snow (recent + forecast), conditions (snow=good, rain=bad). Implement compute_ski_score and expose GET /scores, GET /scores/{resort_name}, GET /health, POST /internal/notify. Add SSE endpoint GET /events that streams weather_data_updated. Use asyncio.Queue to broadcast when /internal/notify is called. Enable CORS for all origins. NWS snowfall is in cm—convert to inches. Use get_db from data_collector.database.

**Frontend** (`frontend/src/App.tsx`):

> Build a React + TypeScript app (Vite) that fetches GET /scores?include_details=true and displays top 3 resorts. Add a "Look up a resort" form that calls GET /scores/{resort_name} (URL-encode). Subscribe to EventSource at /events and refetch scores on weather_data_updated. Use import.meta.env.DEV and /api for dev proxy. Handle loading and error states.

**Tests** (`tests/test_api_collector.py`, `conftest.py`, `test_integration_analyzer.py`):

> Write pytest tests for POST /fetch. Mock httpx.Client via @patch so no real NWS calls. Provide fake JSON for points, forecast, gridpoint URLs. Override get_db with fixture session. Create seeded_db fixture with Location "Test Resort", one WeatherRecord, one SnowRecord. Integration test: use seeded_db, call GET /scores, assert Test Resort score 0–100 and details present.

**Scheduler** (`scheduler.py`):

> Write a Python script that runs in Docker. On startup, poll http://api:8000/health until healthy (up to 120s, every 5s). Then POST http://api:8000/fetch, then POST http://analyzer:8001/internal/notify. Repeat every 2 hours. Use urllib.request. Log and handle errors.

### APA Citation
Cursor. (2026). Cursor Composer (Version 1.5) [Large language model]. https://cursor.com/